**Pod-A cannot reach Pod-B ‚Äî how do you troubleshoot?**

**Answer-** I troubleshoot pod-to-pod connectivity by checking pod status, DNS resolution, service configuration, network policies, CNI health, and namespace isolation‚Äîmoving from application layer down to networking.

#### 1Ô∏è‚É£ Confirm both pods are actually running

```bash
kubectl get pods -A -o wide
```

**Expected Output:**

```
NAME      STATUS    ROLES    AGE    IP           NODE
pod-a     Running   <none>   5m     10.244.1.2   node-1
pod-b     Running   <none>   5m     10.244.2.3   node-2
```

Check:
- STATUS = Running
- Pods scheduled on different nodes? (important later)

If Pod-B is:
- CrashLoopBackOff
- NotReady
‚û°Ô∏è Network is not the issue yet

#### 2Ô∏è‚É£ Verify Pod-B is listening on the expected port

From **inside Pod-B:**

```bash
kubectl exec -it pod-b -- netstat -tulnp
```

Common mistake:
- App listens on localhost instead of 0.0.0.0

‚ùå Localhost ‚Üí unreachable from other pods

‚úÖ 0.0.0.0 ‚Üí reachable from all pods

#### 3Ô∏è‚É£ Test direct Pod IP connectivity

From **Pod-A:**

```bash
kubectl exec -it pod-a -- curl <POD-B-IP>:<PORT>
```

Results:
- ‚ùå Fails ‚Üí network or policy issue
- ‚úÖ Works ‚Üí Service/DNS issue

#### 4Ô∏è‚É£ If using Service, check Service & endpoints

```bash
kubectl get svc
kubectl get endpoints <service-name>
```

‚ùå Empty endpoints = readiness probe failing
‚ùå Wrong port mapping = connection refused

#### 5Ô∏è‚É£ Check DNS resolution

From **Pod-A:**

```bash
kubectl exec -it pod-a -- nslookup pod-b
kubectl exec -it pod-a -- nslookup service-name
```

If DNS fails:
- CoreDNS issue
- Wrong namespace
- Using short name instead of FQDN

Correct DNS format:

```code
service-name.namespace.svc.cluster.local
```

#### 6Ô∏è‚É£ Namespace mismatch

‚úÖ Use:

```bash
service-name.other-namespace.svc.cluster.local
```

#### 7Ô∏è‚É£ Check NetworkPolicies

```bash
kubectl get networkpolicy -A
```

If **any NetworkPolicy** exists in the namespace:

- Default behavior becomes deny
- Explicit allow rules required

#### 8Ô∏è‚É£ Verify CNI plugin health

In Kubernetes, pod-to-pod traffic is handled by CNI.

Check CNI pods:

```bash
kubectl get pods -n kube-system -l k8s-app=calico-node
```

If CNI is broken ‚Üí no pod networking at all

#### 9Ô∏è‚É£ Check Node-to-Node Connectivity

If pods are on different nodes, check routing:

```bash
# From node where pod-a runs
telnet <POD-B-IP> <PORT>
```

If this fails:
- Check node firewall
- Check Calico/Flannel routing rules
- Check node security groups (cloud)

#### üîü Check kube-proxy Health

```bash
kubectl get pods -n kube-system -l k8s-app=kube-proxy
```

kube-proxy handles Service IP routing.


### üéØ Quick Troubleshooting Checklist

1. **Pods Running?** ‚Üí `kubectl get pods -A`
2. **Listening on 0.0.0.0?** ‚Üí `kubectl exec pod-b -- netstat -tulnp`
3. **Direct IP Reachable?** ‚Üí `kubectl exec pod-a -- curl <IP>`
4. **Service Exists?** ‚Üí `kubectl get svc`
5. **Endpoints Healthy?** ‚Üí `kubectl get endpoints <service>`
6. **DNS Working?** ‚Üí `kubectl exec pod-a -- nslookup pod-b`
7. **NetworkPolicy Blocking?** ‚Üí `kubectl get networkpolicy -A`
8. **CNI Healthy?** ‚Üí `kubectl get pods -n kube-system -l k8s-app=calico-node`
9. **Node Routing OK?** ‚Üí `telnet <IP> <PORT>` from node
10. **Kube-proxy Running?** ‚Üí `kubectl get pods -n kube-system -l k8s-app=kube-proxy`

---

### üí° Common Pitfalls

- ‚ùå App listening on localhost
- ‚ùå Missing Service endpoints
- ‚ùå NetworkPolicy blocking traffic
- ‚ùå DNS resolution issues
- ‚ùå CNI plugin not running
- ‚ùå Node-level firewall blocking
- ‚ùå Wrong namespace
- ‚ùå Readiness probe failing

---

### Contributors
[![Yogendra Pratap Singh][yogendra_avatar]][yogendra_homepage]<br/>[Yogendra Pratap Singh][yogendra_homepage] 

  [yogendra_homepage]: https://www.linkedin.com/in/yogendra-pratap-singh-41630716b/
  [yogendra_avatar]: https://img.cloudposse.com/75x75/https://github.com/PratapSingh13.png